---
title: "Les rescap?s du Titanic"
author: "Par Robin"

output: pdf_document
---



On dispose d'une base d'apprentissage pr?sentant 12 caract?ristiques de 891 passagers du Titanic (11 variables explicatives + l'indicatrice de leur survie, ou pas).
L'objectif est de pr?dire la survie, ou la mort, des 418 passagers de la base de test.

Les variables sont les suivantes : 
<ul>
<li>**PassengerID** : Num?ro du passager</li>
<li>**Pclass** : Classe du ticket du passager (1ere classe, 2nd classe...)</li>
<li>**Name** : Nom complet du passager</li>
<li>**Sex** : Sexe du passager</li>
<li>**Age** : Age du passager</li>
<li>**SibSp** : Nombre de proches/conjoints du passager ? bord du titanic</li>
<li>**Parch** : Nombre de parents/enfants du passager ? bord du titanic</li>
<li>**Ticket** : Num?ro de ticket </li>
<li>**Fare** : Prix du ticket du passager</li>
<li>**Cabin** : Num?ro de cabine du passager</li>
<li>**Embarked** : Port d'embarcation du passager (C = Cherbourg, Q = Queenstown, S = Southampton) </li>
<li>**Survived** : Indicatrice de survie du passager (0= Mort, 1=Survie) </li>
</ul>

## Chargement et pr?paration des donn?es

On charge les packages qui seront utiles.
```{r include=FALSE}
library(tidyverse)
library(caret)
library(randomForest)
library(xgboost)
library(Matrix)
```

On importe et pr?pare les donn?es.

```{r}
train <- read.csv("D://Documents//Kaggle//titanic//train.csv",header=T,sep=",",na.strings = c("NA", ""))
test <- read.csv("D://Documents//Kaggle//titanic//test.csv",header=T,sep=",",na.strings = c("NA", ""))
test <- mutate(test, Survived=NA)
full <- rbind(train,test)
```

Jettons un rapide coup d'oeil ? la structure des donn?es :

```{r}
str(full)
```

Les variables **PassengerId**,**Survived** et **Pclass**, qui sont qualitatives, sont actuellement consid?r?es par R comme ?tant quantitatives. Rem?dions ? ?ela.

```{r warning=F}
full <- full %>% mutate(Survived = as.factor(Survived),
                        PassengerId = as.factor(PassengerId),
                        Pclass = as.factor(Pclass))  

```



## Analyse exploratoire

Explorons et visualisions un peu nos donn?es pour voir ce ? quoi on a affaire ! 


# Valeurs manquantes

V?rifions la pr?sence de valeurs manquantes dans notre jeu de donn?es. 
```{r}
colSums(is.na(full))
```

Les variables **Age**, **Fare**, **Cabin** et **Embarked** pr?sentent des valeurs manquantes, on garde ?a en t?te pour notre exploration et on corrigera ce probl?me pour chaque variable lors de la phase de feature engineering.


# Age et sexe des passagers

Regardons la r?partition des passagers selon leur age et leur sexe  
<br> 

```{r, echo=F, warning=F, out.width="80%"}
train <- train %>% mutate(Survived=as.factor(Survived))
train.nona<- train[!is.na(train$Age),] %>% mutate(Pclass=as.factor(Pclass))

ggplot(train.nona, aes(x=Sex,y=Age,fill=Sex)) + 
  geom_violin() +  
  stat_summary(fun.y=mean, geom="point") +
  scale_fill_manual(values=c("#E69F00", "#56B4E9"))+
  ggtitle('Violin plot des passagers par age et sexe')
```

Les hommes sont plus nombreux que les femmes (843 hommes contre 466 femmes) et celles-ci sont en moyenne un peu plus jeunes que les hommes. Regardons comment l'age est r?parti au sein des classes de voyage (1ere classe, ...).

```{r, echo=F}
ggplot(train.nona) + 
  geom_boxplot(aes(y=Age,x=Pclass,fill=Pclass)) +  
  ggtitle('Boxplot des ages par classe')
```

La classe croit avec l'age, les passagers en premiere classe ont tendance ? etre plus ag?s que les autres. Ceux de troisieme classe sont les plus jeunes.
<br>

Quid du taux de survie en fonction de l'age et du sexe ?


```{r, warning=F, echo=F}
ggplot(train.nona) +
  geom_density(aes(x=Age, fill = Survived), alpha = 0.5) +
  facet_wrap(~Sex)+
  ggtitle('Densit? du taux de survie en fonction de l\'age, pour chaque sexe')
```


```{r, echo=F}
ggplot(train) + 
  geom_bar(aes(x=Sex, fill=Survived, color=Survived), position='fill', show.legend=F)+
  scale_fill_manual(values = c(NA, '#3374FF')) +
  scale_color_manual(values = c(NA, 'black'))+
  ylab('Taux de survie')+
  xlab("Sexe")+
  ggtitle('Taux de survie par sexe')
```


```{r, echo=F}
train.tranche <- data.frame(train.nona, tranche = cut(train.nona$Age, seq(0, 80, 10)))

ggplot(train.tranche) +
  geom_bar(aes(x=tranche, fill=Survived, color=Survived), position='fill', show.legend=F) +
  scale_fill_manual(values = c(NA, '#3374FF')) +
  scale_color_manual(values = c(NA, 'black'))+
  ylab('Taux de survie')+
  xlab("Tranche d\'age")+
  ggtitle('Taux de survie par tranche d\'age')
```

Sans surprise, les femmes ont beaucoup plus surv?cu au naufrage que les hommes, et le taux de survie est ?galement meilleur chez les jeunes enfants. Apr?s tout \"les femmes et les enfants d\'abord \", un ?quipage de gentleman donc.

## Prix, classe du ticket et port d'embarcation

Trois des variables ? notre disposition, **Fare**, **Pclass** et **Embarked** donnent des informations sur le moyen d'acc?s des voyageurs au navire (i,e leur ticket), jettons un oeil ? ces variables.
<br>

Regardons ? quel point la classe choisit impacte le prix du ticket.
<br>

```{r, echo=F, warning=F}
ggplot(full) +
  geom_density(aes(x=Fare, fill = Pclass), alpha = 0.5) +
  xlim(0,100) +
  ggtitle('Densit? du prix du ticket, par classe')
```

Maintenant, l'influence du port d'embarcation sur le prix du ticket.
<br>

```{r, echo=F, warning=F}
ggplot(full[!is.na(full$Embarked),]) +
  geom_density(aes(x=Fare, fill = Embarked), alpha = 0.5) +
  xlim(0,100) +
  ggtitle('Densit? du prix du ticket, par port d\'embarcation')
```

On remarque sur les deux graphiques le m?me pic aux alentours de 10 livres. Il semblerait que les passagers ayant embarqu?s Queenstown soient presque tous en 3eme classes. V?rifions cela avec une table de contingence : 

```{r}
table(full$Pclass,full$Embarked)
```

Effectivement, 113 des 123 passagers ayant embarqu?s ? Queenstown sont en 3eme classe. Les autres ports sont plus r?partis au sein des 3 classes.

## Feature Engineering

C'est le moment de traiter les valeurs manquantes et d'arranger nos variables pour en extraire le maximum d'information.

### PassengerId et Ticket

Les variables **PassengerId** et **Ticket** sont toutes deux des identifiants uniques, r?f?rant ? un seul passager. Aucune information ? en tirer pour notre mod?lisation, on s'en d?barasse donc.

```{r}
full <- full %>% select(-PassengerId, -Ticket)
```


### Creation d'une variable pour le titre du passager

Le nom du passager en lui m?me est totalement inutile ? notre mod?lisation : il y a autant de noms que de passagers (heureusement !) et entrainer un mod?le dessus reviendrait ? plonger dans l'overfitting. N?anmoins un ?lement est int?r?ssant dans **Name**, il s'agit du titre du passager (Mr, Miss, Master...) qui apparait dans le nom. Il semble raisonable de penser que selon leur rang, les passagers ont pu b?n?ficier de traitements diff?rents lors de l'?vacuation du navire. On va donc creer une nouvelle variable **Title** qui pr?cise le titre de chaque passager.  
<br>

```{r, warning=F}
full <- full %>% separate(Name, c('osef1', "subname"), sep = ", ") %>%
  separate(subname, c("Title", 'osef2'), sep = ". ") %>% 
  select(-osef1,-osef2) %>% 
  mutate(Title=as.factor(Title))

summary(full$Title)
```

Il y a 18 titres diff?rents, dont la plupart n'apparaissent qu'une ou deux fois. On ne gardera que les 4 titres les plus fr?quents et on regroupera les autres dans une modalit? \"Other\".

```{r}
full$Title <- fct_lump(full$Title,4)

summary(full$Title)
```

Notons au passage que l'on c'est d?barass? de la variable **Name**, devenue inutile.

### Le cas Cabin

La cas de la variable **Cabin** est un peu particulier. Cette variable pr?cise la cabine qu'occupait chaque membre d'?quipage sous la forme *Num?ro du pont + Num?ro de cabine* (Exemples : A15, C18...). Chaque passager a donc une modalit? diff?rente, ce qui est inutile pour le mod?le. De plus, les trois quarts des valeurs (77%) sont manquantes. 

J'ai d'abord pens? exclure purement et simplement la variable de la mod?lisation, mais je trouvais tout de m?me dommage de perdre l'information qu'elle apporte. Une autre id?e ?tait de la transformer en "indicatrice de si on connaissait la cabine du passager ou non", i.e une variable qui vaudrait 0 si la cabine du passager ?tait inconnu, 1 si on la connaissait. Cela ne c'est pas av?r? satisfaisant.

Finalement une solution qui semble int?r?ssante est d'extraire la lettre correspondante au num?ro du pont (lorsque celle ci est connu) et de se d?barasser du num?ro de cabine. L'id?e ?tant que selon le pont ou ?tait situ? leur cabine, les passagers aient pu avoir plus ou moins de difficult? ? ?vacuer le navire. On cr?e ainsi une nouvelle variable, **Desk**. Lorsque la donn?e est manquante, on pr?cisera simplement la modalit? "Other"


```{r}
full <- full %>% 
  separate(Cabin,c("Desk","osef"),1) %>%
  select(-osef)

full$Desk[is.na(full$Desk)] <- "Other"

summary(as.factor(full$Desk))
```

Les ponts G et T ?tant sous repr?sent?s, ils risquent de nous embeter pour la suite et n'auront presque aucune influence sur la mod?lisation. On les regroupe avec la modalit? Other.

```{r}
full$Desk <- fct_other(full$Desk, drop=c("G","T",'Other'))

summary(full$Desk)
```

Il est alors l?gitime de v?rifier que le taux de survie varie selon les ponts

```{r, echo=F}
ggplot(full[1:891,]) + 
  geom_bar(aes(x=Desk, fill=Survived, color=Survived), position='fill', show.legend=F) +
  scale_fill_manual(values = c(NA, '#3374FF')) +
  scale_color_manual(values = c(NA, 'black'))+
  ylab('Taux de survie')+
  xlab("Pont")+
  ggtitle('Taux de survie par pont')
```

Ce qui est bien le cas ! 

### Regroupement de Sibsp et Parch

Les variables **SibSp** et **Parch** n'ont pas reelement lieu d'etre s?par?s. L'une pr?cise le nombre de parents ou enfants ? bord, l'autre indique le nombre de conjoints ou autre proche ? bord. Au final, ces deux variables refletent une m?me chose : la pr?sence (et leur nombres) de membres de la m?me famille que le passager en question ? bord du Titanic. Par cons?quent, on remplacera ces deux variables par une unique nouvelle variable, **Family** qui sera la somme de ces deux la.

```{r}
full <- full %>% 
  mutate(Family = SibSp + Parch) %>% 
  select(-SibSp, -Parch) 

summary(as.factor(full$Family)) # Repartition du nombre de membres de la famille
```



```{r, echo=F}
ggplot(full[1:891,]) + 
  geom_bar(aes(x=as.factor(Family), fill=Survived, color=Survived), position='fill', show.legend=F) +
  scale_fill_manual(values = c(NA, '#3374FF')) +
  scale_color_manual(values = c(NA, 'black'))+
  ylab('Taux de survie')+
  xlab("Pont")+
  ggtitle('Taux de survie des passagers selon le nombre de leur proches ? bord du Titanic')

```

Contrairement ? ce que j'aurai pens?, le taux de survie ne d?croit pas avec le nombre de membres de la famille. Les familles de 4 personnes ont le mieux surv?cu au naufrages (3 membres de familles + le passager). N?anmoins, le taux de survie chute ensuite ? mesure que la famille s'aggrandit, et les 2 grandes familles ? bord du navire (8 et 11 membres) ont ?t? d?cim?es. Le faible taux de survie chez les personnes seules peut s'expliquer par le fait que la plupart d'entre elles sont des membres de l'?quipages, qui ont donc ?t? les derniers ? etre ?vacu?s.


### Remplissage des valeurs manquantes d'Embarked

Puisqu'il n'y a que 2 valeurs manquantes ? la variable **Embarked**, il n'est pas n?c?ssaire de se prendre la t?te ? pr?dire leur valeur puisque l'impact des celles-ci sur le mod?le final sera minime. On se contentera donc de leur attribuer la modalit? la plus fr?quente.

```{r}
summary(full$Embarked)

full$Embarked[which(is.na(full$Embarked))] <- 'S'
```

### L'unique valeur manquante de Fare

Le prix du ticket est manquant pour un seul passager. S'agissant un cas isol?, on se contentera de lui attribuer le prix moyen d'un ticket.

```{r}
full$Fare[which(is.na(full$Fare))] <- mean(full$Fare, na.rm=T)
```


### Regression des valeurs manquantes de Age

La variable **Age** comporte environ 20% de valeurs manquantes, ce qui est trop pour ?tre remplac? par une unique valeur du type moyenne, m?diane ou autre. On va par cons?quent pr?dire ces valeurs manquantes par foret al?atoire.

```{r}
index.na <- which(is.na(full$Age))
full.nona <- select(full[-index.na,], -Survived)
full.na <- select(full[index.na,], -Survived)

model.rf.age <-randomForest(Age~., data=full.nona, ntree=500) 

full$Age[index.na] <- predict(model.rf.age, full.na)

```

Notre jeu de donn?es est maintenant tout beau tout propre. On a toujours les 1309 lignes de d?part, et on dispose maintenant de 9 colonnes : 8 variables explicatives + la variable ? pr?dire **Survived**. 

```{r}
str(full)
head(full)
```

## Mod?lisation et pr?dictions

Pr?parons nos donn?es pour la phase de mod?lisation en s?parant base d'apprentissage et base de test, ainsi que variables explicatives et variables ? expliquer.

```{r}
X.train <- full %>% 
  filter(!is.na(Survived)) %>%
  select(-Survived)

Y.train <- (full %>% 
  filter(!is.na(Survived)) %>% 
  select(Survived))$Survived 

X.test <- full %>%
  filter(is.na(Survived)) %>% 
  select(-Survived)

```

### R?gression logistique

On commence par la bonne vieille regression logistique qui servira de reference. M?me si la regression logistique n'a aucun hyper-parametre a regler, je passe quand m?me par de la validation crois?e pour avoir une estimation de l'accuracy du modele.

```{r}

log.ctrl <- trainControl(method = 'repeatedcv',
                 number = 10,
                 repeats = 3)

model.log <- train(x = X.train,
                   y = Y.train,
                   method = "glm",
                   metric = "Accuracy",
                   trControl = log.ctrl)

model.log

```

Avec ce mod?le on pr?dit la survie des passagers de la base de test, que l'on note dans un fichier csv afin de le soumettre sur kaggle.

```{r}
pred.log <- predict(model.log, X.test)

df_log <- data.frame(PassengerId = test$PassengerId, Survived=pred.log)
write.csv(df_log, file="D://Documents//Kaggle//titanic//df_log.csv", row.names =F, quote=F)
```

Hop on upload ?a sur kaggle, et on obtient une accuracy de **0.7751**. Voyons si on peut faire mieux autrement.

### QDA

Essayons une analyse discriminante quadratique, toujours avec validation crois?e.

```{r}
qda.ctrl <- trainControl(method = 'repeatedcv',
                 number = 10,
                 repeats = 3)

model.qda <- train(x = data.matrix(X.train),
                   y = Y.train,
                   method = "qda",
                   metric = "Accuracy",
                   trControl = qda.ctrl)

model.qda
```

La validation crois?e est moins optimiste sur l'accuracy de QDA que sur la regression logistique. Regardons ce qu'il en est en realisant les predictions de la base de test et en les soumettant ? kaggle.


```{r}
pred.qda <- predict(model.qda, data.matrix(X.test))

df_qda <- data.frame(PassengerId = test$PassengerId, Survived=pred.qda)
write.csv(df_qda, file="D://Documents//Kaggle//titanic//df_qda.csv", row.names =F, quote=F)
```

Et on obtient un score de **0.7846** ! QDA a donc mieux perform? ici que la regression logistique. 


### XGboost

Passons au gros du morceau, XGboost. L'id?e ici est de montrer que les m?thodes de boosting, bien qu'elles demandent plus de travail, peuvent obtenir des r?sultats plus performants que les m?thodes statistiques traditionelles.
<br>

Tout d'abord, xgboost ne gere pas directement les variables qualitatives, il est n?c?ssaire de passer par une matrice de design pour recoder celles-ci.

```{r}
X.train.xgb <- sparse.model.matrix(~.-1,data=X.train)

Y.train.xgb <- as.numeric(Y.train)-1

X.test.xgb <- sparse.model.matrix(~.-1,data=X.test)
```

XGboost est disponible directement dans le package du m?me nom, et dispose aussi d'une implementation dans Caret. Le package natif pr?sente l'avantage d'avoir une architecture propre qui le rend tr?s rapide, et dispose d'une fonction de validation crois?e, mais celle-ci ne permet de regler que *nrounds*, le nombre d'it?rations, alors que Caret permet le reglage d'un plus grand nombres d'hyper-parametres, en particulier *max_depth* et *min_child_weight* dont le reglage permet de limiter l'overfitting, ainsi que *eta* la vitesse d'apprentissage.


```{r, warning=F, echo=F}
xgb.ctrl <- trainControl(method="cv",
                         number=5)


xgb.grid <- expand.grid(nrounds = c(75,100,150),
                        eta = c(0.01,0.05,0.1),
                        max_depth = c(6,8,10),
                        gamma=0,
                        colsample_bytree=seq(0.5,1,0.1),
                        min_child_weight=c(1,3,5),
                        subsample=seq(0.5,1,0.1))


model.xgb.cv <- train(x = X.train.xgb,
                      y = Y.train,
                      method = 'xgbTree',
                      tuneGrid = xgb.grid,
                      trControl = xgb.ctrl)
```


"The final values used for the model were nrounds = 100, max_depth = 8, eta = 0.1, gamma = 0, colsample_bytree = 0.5, min_child_weight = 3 and subsample = 0.5.". On configure alors le modele avec ces parametres.

```{r, message=F, echo=F}
dtrain <- xgb.DMatrix(data = X.train.xgb , label = Y.train.xgb)
dtest <- xgb.DMatrix(data = X.test.xgb)

params <- list(max.depth = 8,
               sumsample = 0.5,
               eta = 0.1,
               colsample_bytree = 0.5,
               min_child_weight = 3,
               gamma = 0)

model.xgb <- xgb.train(data = dtrain,
                       params = params,
                       nrounds = 100,
                       objective = "binary:logistic")

```

Il est alors possible ? l'aide du packages xgboost d'afficher l'importance de chaque variable : 

```{r, echo = F}
set.seed(15)
model.xgb.importance <- xgboost(data = data.matrix(X.train),
                                label = Y.train.xgb,
                                params = params,
                                nrounds = 100,
                                verbose = F,
                                objective = "binary:logistic")

names <- names(model.xgb.importance$feature_names)
importance <- xgb.importance(names,model=model.xgb.importance)

xgb.ggplot.importance(importance,n_clusters=3) +
  ggtitle('Importance des variables dans la mod?lisation')
```
Il se d?gage 3 classes d'importances de variables : le sexe est la variable ayant la plus grande importance dans le mod?le. Le prix du ticket et l'age des passagers ont aussi eu une importance assez cons?quente, tandis que les autres variables sont bien moins porteuses d'information.


```{r}
pred.xgb <- predict(model.xgb, X.test.xgb) 
pred.xgb <- ifelse(pred.xgb < 0.5, 0, 1)

df_xgb <- data.frame(PassengerId = test$PassengerId, Survived=pred.xgb)
write.csv(df_xgb, file="D://Documents//Kaggle//titanic//df_xgb.csv", row.names =F, quote=F)
```

On soumet ?a ? Kaggle et verdict : Accuracy de **0.7914**, mieux que les m?thodes pr?c?dentes donc. 

Des id?es d'am?liorations ? 


